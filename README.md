# Information Retrieval Assignments

## Overview
This repository contains several assignments focused on Information Retrieval techniques applied to Persian text. The main objectives are to implement various retrieval models and text-processing techniques using Python libraries.

## Assignments
### 1. [Persian Text Mining with Hazm, Parsivar, and DadmaTools](./HW1)
- Perform text mining techniques on Persian news articles using three different libraries.
- Data acquisition, normalization, tokenization, and stemming of Persian text.

### 2. [Text Indexing with Hazm in Persian News Articles](./HW2)
- Demonstrate text indexing and preprocessing on Persian news articles using the Hazm library.
- The project downloads Persian news articles, preprocesses them with Hazm, creates a posting list, visualizes token frequencies, and analyzes the most frequent tokens.

### 3. [Information Retrieval Models on Persian text](./HW3)
- Index Persian news articles using Hazm to build a posting list and analyze token frequencies.
- Create a posting list linking terms to document frequencies and visualize token frequencies with statistical measures.

### 4. [Web Crawling Assignment](./HW4)
- Crawl the website ketabrah.ir to extract structured information about books.
- Extract data such as subject, title, author, translator, publisher, price, year of publication, user rating, and number of reviews. Store the data in a CSV file.

## Libraries Used
- **Python**: Hazm, Parsivar, DadmaTools, BeautifulSoup, Scrapy, and Selenium.
- **Requirements**: Python 3.x and relevant libraries.

## Usage
1. Clone the repository:
   ```bash
   git https://github.com/bitua79/information_retrieval_assignment.git
   ```
2. Navigate to the relevant assignment folder.
3. Follow the instructions in each assignment's README for execution.

## Notes
- Ensure all required libraries are installed using pip before running the assignments.
