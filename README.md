# Information Retrieval Assignments

## Overview

This repository contains several assignments focused on Information Retrieval techniques applied to Persian text. The main objectives are to implement various retrieval models and text-processing techniques using Python libraries.

## Assignments

### 1. [Persian Text Mining with Hazm, Parsivar, and DadmaTools](./HW1)

- Perform text mining techniques on Persian news articles using three different libraries.
- Data acquisition, normalization, tokenization, and stemming of Persian text.

### 2. [Text Indexing with Hazm in Persian News Articles](./HW2)

- Demonstrate text indexing and preprocessing on Persian news articles using the Hazm library.
- The project downloads Persian news articles, preprocesses them with Hazm, creates a posting list, visualizes token frequencies, and analyzes the most frequent tokens.

### 3. [Information Retrieval Models on Persian text](./HW3)

- Index Persian news articles using Hazm to build a posting list and analyze token frequencies.
- Create a posting list linking terms to document frequencies and visualize token frequencies with statistical measures.

### 4. [Web Crawling Assignment](./HW4)

- Crawl the website ketabrah.ir to extract structured information about books.
- Extract data such as subject, title, author, translator, publisher, price, year of publication, user rating, and number of reviews. Store the data in a CSV file.

## Libraries Used

- **Python**: Hazm, Parsivar, DadmaTools, BeautifulSoup, Scrapy, and Selenium.
- **Requirements**: Python 3.x and relevant libraries.

## Usage

1. Clone the repository:
   ```bash
   git https://github.com/gnozadi/information_retrieval_assignment.git
   ```
2. Navigate to the relevant assignment folder.
3. Follow the instructions in each assignment's README for execution.

## Notes

- Ensure all required libraries are installed using pip before running the assignments.
